# 模块7: 三级审核系统
import re
import json
import time
import logging
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
import threading
from collections import defaultdict
from 模块2_配置管理 import 获取配置管理器
from 模块5_智能生成核心 import 生成结果

class 审核模式(Enum):
    开启 = "开启"
    关闭 = "关闭"
    自定义 = "自定义"

class 风险等级(Enum):
    安全 = "安全"
    低风险 = "低风险"
    中风险 = "中风险"
    高风险 = "高风险"
    危险 = "危险"

class 内容类型(Enum):
    文本 = "文本"
    图像 = "图像"
    音频 = "音频"
    视频 = "视频"

@dataclass
class 审核结果:
    """审核结果数据结构"""
    审核ID: str
    内容类型: 内容类型
    风险等级: 风险等级
    风险评分: float
    审核模式: 审核模式
    通过: bool
    发现的问题: List[Dict[str, Any]]
    自定义关键词命中: List[str]
    审核时间: float
    审核详情: Dict[str, Any]
    建议措施: List[str]

@dataclass
class 安全事件:
    """安全事件记录"""
    事件ID: str
    内容类型: 内容类型
    风险等级: 风险等级
    内容摘要: str
    审核结果: 审核结果
    处理状态: str
    发生时间: float
    处理时间: Optional[float]
    处理人员: Optional[str]
    处理措施: Optional[str]

class Google级安全识别器:
    """Google级安全内容识别器"""
    def __init__(self):
        self.配置管理器 = 获取配置管理器()
        self.日志器 = logging.getLogger('Google级安全识别器')
        
        # 多维度安全规则库
        self.安全规则库 = self.初始化安全规则库()
        self.语义分析库 = self.初始化语义分析库()
        self.上下文理解器 = self.初始化上下文理解器()
        
        # 风险模式识别
        self.风险模式库 = self.初始化风险模式库()
        
    def 初始化安全规则库(self) -> Dict[str, Dict[str, Any]]:
        """初始化多维度安全规则库"""
        return {
            "政治敏感": {
                "关键词": [
                    "国家领导人", "政府", "政党", "政治", "民主", "自由", "人权",
                    "革命", "抗议", "示威", "政权", "统治", "专政", "独裁"
                ],
                "风险权重": 0.9,
                "上下文敏感": True,
                "语义分析": True
            },
            "暴力内容": {
                "关键词": [
                    "杀人", "暴力", "血腥", "恐怖", "爆炸", "枪支", "武器",
                    "屠杀", "伤害", "攻击", "殴打", "战争", "战斗"
                ],
                "风险权重": 0.8,
                "上下文敏感": True,
                "语义分析": True
            },
            "色情内容": {
                "关键词": [
                    "色情", "淫秽", "性爱", "裸体", "强奸", "猥亵", "淫乱",
                    "情色", "性行为", "性描写", "露骨"
                ],
                "风险权重": 0.85,
                "上下文敏感": True,
                "语义分析": True
            },
            "违法内容": {
                "关键词": [
                    "毒品", "赌博", "诈骗", "黑客", "盗窃", "抢劫", "贪污",
                    "腐败", "走私", "贩毒", "吸毒"
                ],
                "风险权重": 0.9,
                "上下文敏感": True,
                "语义分析": True
            },
            "歧视内容": {
                "关键词": [
                    "种族歧视", "性别歧视", "地域歧视", "宗教歧视", "民族歧视",
                    "歧视女性", "歧视黑人", "地域黑", "种族主义"
                ],
                "风险权重": 0.7,
                "上下文敏感": True,
                "语义分析": True
            },
            "自残自杀": {
                "关键词": [
                    "自杀", "自残", "自尽", "割腕", "上吊", "跳楼", "抑郁症",
                    "心理问题", "绝望", "不想活了"
                ],
                "风险权重": 0.95,
                "上下文敏感": True,
                "语义分析": True
            },
            "恐怖主义": {
                "关键词": [
                    "恐怖组织", "恐怖袭击", "极端主义", "圣战", "炸弹", "人肉炸弹",
                    "恐怖分子", "基地组织", "ISIS"
                ],
                "风险权重": 1.0,
                "上下文敏感": True,
                "语义分析": True
            },
            "虚假信息": {
                "关键词": [
                    "谣言", "假新闻", "虚假信息", "误导", "欺骗", "造假",
                    "不实信息", "编造", "虚构事实"
                ],
                "风险权重": 0.6,
                "上下文敏感": True,
                "语义分析": True
            }
        }
    
    def 初始化语义分析库(self) -> Dict[str, Any]:
        """初始化语义分析库"""
        return {
            "否定词": ["不", "没", "无", "非", "未", "勿", "莫", "别"],
            "程度词": ["非常", "极其", "十分", "特别", "相当", "比较", "稍微"],
            "情感词": {
                "正面": ["好", "优秀", "美丽", "善良", "正义", "勇敢"],
                "负面": ["坏", "恶劣", "丑陋", "邪恶", "卑鄙", "懦弱"]
            },
            "上下文标记": ["但是", "然而", "不过", "虽然", "尽管", "即使"]
        }
    
    def 初始化上下文理解器(self) -> Dict[str, Any]:
        """初始化上下文理解器"""
        return {
            "文学语境": ["小说", "故事", "剧情", "角色", "设定", "虚构"],
            "教育语境": ["教育", "学习", "知识", "教学", "课程"],
            "新闻语境": ["报道", "新闻", "记者", "时事", "政治"],
            "学术语境": ["研究", "论文", "学术", "科学", "实验"]
        }
    
    def 初始化风险模式库(self) -> Dict[str, Any]:
        """初始化风险模式识别库"""
        return {
            "激进言论": {
                "模式": r'.*[必须一定务必].*[打倒推翻消灭].*',
                "风险等级": 风险等级.高风险
            },
            "自残倾向": {
                "模式": r'.*[想希望打算].*[死自杀结束生命].*',
                "风险等级": 风险等级.危险
            },
            "仇恨言论": {
                "模式": r'.*[所有全部一切].*[都应该必须].*[消失灭亡].*',
                "风险等级": 风险等级.高风险
            },
            "极端主义": {
                "模式": r'.*[唯一绝对].*[真理正确].*[其他所有].*[错误谬误].*',
                "风险等级": 风险等级.中风险
            }
        }
    
    def 深度语义扫描(self, 内容: str, 上下文: str = "") -> Dict[str, Any]:
        """深度语义内容扫描"""
        扫描结果 = {
            "表面风险": [],
            "深层风险": [],
            "语义分析": {},
            "上下文风险评估": 0.0,
            "总体风险评分": 0.0
        }
        
        try:
            # 表面关键词扫描
            表面风险 = self.表面关键词扫描(内容)
            扫描结果["表面风险"] = 表面风险
            
            # 深层语义分析
            深层风险 = self.深层语义分析(内容, 上下文)
            扫描结果["深层风险"] = 深层风险
            
            # 语义特征提取
            语义特征 = self.提取语义特征(内容)
            扫描结果["语义分析"] = 语义特征
            
            # 上下文风险评估
            上下文风险 = self.评估上下文风险(内容, 上下文)
            扫描结果["上下文风险评估"] = 上下文风险
            
            # 计算总体风险评分
            总体风险 = self.计算总体风险评分(表面风险, 深层风险, 上下文风险)
            扫描结果["总体风险评分"] = 总体风险
            
            return 扫描结果
            
        except Exception as e:
            self.日志器.error(f"深度语义扫描失败: {e}")
            return 扫描结果
    
    def 表面关键词扫描(self, 内容: str) -> List[Dict[str, Any]]:
        """表面关键词扫描"""
        发现的风险 = []
        
        for 风险类型, 规则 in self.安全规则库.items():
            命中关键词 = []
            
            for 关键词 in 规则["关键词"]:
                if 关键词 in 内容:
                    命中关键词.append(关键词)
            
            if 命中关键词:
                风险项 = {
                    "风险类型": 风险类型,
                    "命中关键词": 命中关键词,
                    "风险权重": 规则["风险权重"],
                    "基础风险分": len(命中关键词) * 0.1 * 规则["风险权重"]
                }
                发现的风险.append(风险项)
        
        return 发现的风险
    
    def 深层语义分析(self, 内容: str, 上下文: str) -> List[Dict[str, Any]]:
        """深层语义分析"""
        深层风险 = []
        
        # 检查否定语境（可能降低风险）
        否定语境风险调整 = self.分析否定语境(内容)
        
        # 检查程度修饰（可能增加风险）
        程度修饰风险调整 = self.分析程度修饰(内容)
        
        # 检查情感倾向
        情感倾向分析 = self.分析情感倾向(内容)
        
        # 检查风险模式
        模式匹配风险 = self.检查风险模式(内容)
        
        if 否定语境风险调整:
            深层风险.append({
                "风险类型": "否定语境调整",
                "描述": "内容处于否定语境中，风险可能降低",
                "风险调整": -否定语境风险调整
            })
        
        if 程度修饰风险调整:
            深层风险.append({
                "风险类型": "程度修饰增强",
                "描述": "内容包含程度修饰词，风险可能增加",
                "风险调整": 程度修饰风险调整
            })
        
        if 情感倾向分析["风险调整"] != 0:
            深层风险.append({
                "风险类型": "情感倾向分析",
                "描述": f"情感倾向: {情感倾向分析['倾向']}",
                "风险调整": 情感倾向分析["风险调整"]
            })
        
        深层风险.extend(模式匹配风险)
        
        return 深层风险
    
    def 分析否定语境(self, 内容: str) -> float:
        """分析否定语境"""
        否定词 = self.语义分析库["否定词"]
        句子列表 = self.分割句子(内容)
        
        否定句子数 = 0
        for 句子 in 句子列表:
            for 否定词 in 否定词:
                if 否定词 in 句子:
                    否定句子数 += 1
                    break
        
        否定比例 = 否定句子数 / len(句子列表) if 句子列表 else 0
        return 否定比例 * 0.3  # 否定语境最多降低30%风险
    
    def 分析程度修饰(self, 内容: str) -> float:
        """分析程度修饰"""
        程度词 = self.语义分析库["程度词"]
        
        程度修饰强度 = 0.0
        for 程度词 in 程度词:
            if 程度词 in 内容:
                # 简单加权：非常类词权重更高
                if 程度词 in ["非常", "极其", "十分"]:
                    程度修饰强度 += 0.1
                else:
                    程度修饰强度 += 0.05
        
        return min(程度修饰强度, 0.5)  # 最多增加50%风险
    
    def 分析情感倾向(self, 内容: str) -> Dict[str, Any]:
        """分析情感倾向"""
        正面词 = self.语义分析库["情感词"]["正面"]
        负面词 = self.语义分析库["情感词"]["负面"]
        
        正面计数 = sum(内容.count(词) for 词 in 正面词)
        负面计数 = sum(内容.count(词) for 词 in 负面词)
        
        if 正面计数 + 负面计数 == 0:
            return {"倾向": "中性", "风险调整": 0.0}
        
        正面比例 = 正面计数 / (正面计数 + 负面计数)
        
        if 正面比例 > 0.7:
            return {"倾向": "积极", "风险调整": -0.2}
        elif 正面比例 < 0.3:
            return {"倾向": "消极", "风险调整": 0.2}
        else:
            return {"倾向": "中性", "风险调整": 0.0}
    
    def 检查风险模式(self, 内容: str) -> List[Dict[str, Any]]:
        """检查风险模式"""
        模式风险 = []
        
        for 模式名, 模式配置 in self.风险模式库.items():
            模式 = 模式配置["模式"]
            if re.search(模式, 内容):
                模式风险.append({
                    "风险类型": "模式匹配",
                    "描述": f"匹配到{模式名}模式",
                    "风险等级": 模式配置["风险等级"],
                    "风险调整": 0.5  # 模式匹配固定增加50%风险
                })
        
        return 模式风险
    
    def 提取语义特征(self, 内容: str) -> Dict[str, Any]:
        """提取语义特征"""
        句子列表 = self.分割句子(内容)
        
        特征 = {
            "句子数量": len(句子列表),
            "平均句长": 0,
            "情感密度": 0,
            "风险词密度": 0,
            "复杂性评分": 0
        }
        
        if 句子列表:
            # 计算平均句长
            总字数 = sum(len(句子) for 句子 in 句子列表)
            特征["平均句长"] = 总字数 / len(句子列表)
            
            # 计算情感密度
            情感词总数 = sum(内容.count(词) for 词 in self.语义分析库["情感词"]["正面"] + self.语义分析库["情感词"]["负面"])
            特征["情感密度"] = 情感词总数 / len(内容) if 内容 else 0
            
            # 计算风险词密度
            风险词总数 = 0
            for 规则 in self.安全规则库.values():
                风险词总数 += sum(内容.count(词) for 词 in 规则["关键词"])
            特征["风险词密度"] = 风险词总数 / len(内容) if 内容 else 0
            
            # 计算复杂性评分（基于句子长度变化和词汇多样性）
            特征["复杂性评分"] = self.计算复杂性评分(内容)
        
        return 特征
    
    def 计算复杂性评分(self, 内容: str) -> float:
        """计算内容复杂性评分"""
        if len(内容) < 50:
            return 0.3
        
        # 句子长度变化
        句子列表 = self.分割句子(内容)
        句长列表 = [len(句子) for 句子 in 句子列表]
        
        if len(句长列表) < 2:
            return 0.5
        
        平均句长 = sum(句长列表) / len(句长列表)
        句长差异 = sum(abs(长度 - 平均句长) for 长度 in 句长列表) / len(句长列表)
        句长变化率 = 句长差异 / 平均句长
        
        # 词汇多样性
        中文词 = re.findall(r'[\u4e00-\u9fa5]{2,}', 内容)
        词汇多样性 = len(set(中文词)) / len(中文词) if 中文词 else 0
        
        复杂性 = (句长变化率 * 0.6 + 词汇多样性 * 0.4)
        return min(复杂性, 1.0)
    
    def 评估上下文风险(self, 内容: str, 上下文: str) -> float:
        """评估上下文风险"""
        上下文风险 = 0.0
        
        # 检查文学语境
        for 语境词 in self.上下文理解器["文学语境"]:
            if 语境词 in 上下文 or 语境词 in 内容:
                上下文风险 -= 0.3  # 文学语境降低风险
                break
        
        # 检查教育语境
        for 语境词 in self.上下文理解器["教育语境"]:
            if 语境词 in 上下文 or 语境词 in 内容:
                上下文风险 -= 0.2  # 教育语境降低风险
                break
        
        # 检查新闻语境
        for 语境词 in self.上下文理解器["新闻语境"]:
            if 语境词 in 上下文 or 语境词 in 内容:
                上下文风险 += 0.2  # 新闻语境增加风险
                break
        
        return 上下文风险
    
    def 计算总体风险评分(self, 表面风险: List[Dict], 深层风险: List[Dict], 上下文风险: float) -> float:
        """计算总体风险评分"""
        基础风险分 = 0.0
        
        # 表面风险分
        for 风险项 in 表面风险:
            基础风险分 += 风险项["基础风险分"]
        
        # 深层风险调整
        风险调整 = 0.0
        for 风险项 in 深层风险:
            风险调整 += 风险项.get("风险调整", 0)
        
        # 上下文风险调整
        风险调整 += 上下文风险
        
        # 计算最终风险分
        最终风险分 = 基础风险分 * (1 + 风险调整)
        return min(最终风险分, 1.0)  # 限制在0-1之间
    
    def 分割句子(self, 内容: str) -> List[str]:
        """分割文本为句子"""
        句子列表 = re.split(r'[。！？!?]', 内容)
        return [句子.strip() for 句子 in 句子列表 if 句子.strip()]

class 视觉内容分析器:
    """视觉内容分析器（模拟实现）"""
    def __init__(self):
        self.配置管理器 = 获取配置管理器()
        self.日志器 = logging.getLogger('视觉内容分析器')
        
        # 图像分析规则（模拟）
        self.图像分析规则 = self.初始化图像分析规则()
    
    def 初始化图像分析规则(self) -> Dict[str, Any]:
        """初始化图像分析规则"""
        return {
            "色情内容": {
                "风险权重": 0.9,
                "描述": "检测裸露或性暗示内容"
            },
            "暴力内容": {
                "风险权重": 0.8,
                "描述": "检测暴力、血腥画面"
            },
            "敏感符号": {
                "风险权重": 0.7,
                "描述": "检测政治敏感符号"
            },
            "恐怖内容": {
                "风险权重": 0.95,
                "描述": "检测恐怖主义相关内容"
            }
        }
    
    def 分析图像内容(self, 图像路径: str) -> Dict[str, Any]:
        """分析图像内容（模拟实现）"""
        # 在实际系统中，这里应该集成真实的图像识别API
        # 由于环境限制，我们返回模拟结果
        
        模拟结果 = {
            "分析状态": "模拟分析完成",
            "检测到的元素": [],
            "风险评分": 0.0,
            "风险等级": 风险等级.安全,
            "置信度": 0.0,
            "分析详情": "这是模拟的图像分析结果"
        }
        
        # 模拟分析逻辑
        try:
            # 检查文件扩展名（模拟内容类型判断）
            文件扩展名 = Path(图像路径).suffix.lower()
            if 文件扩展名 in ['.jpg', '.jpeg', '.png', '.gif']:
                # 模拟风险检测
                随机风险 = hash(图像路径) % 100 / 100.0  # 基于文件名的伪随机风险
                
                if 随机风险 > 0.7:
                    模拟结果["风险评分"] = 随机风险
                    模拟结果["风险等级"] = 风险等级.高风险
                    模拟结果["检测到的元素"] = ["模拟检测到潜在敏感内容"]
                    模拟结果["置信度"] = 0.8
                elif 随机风险 > 0.4:
                    模拟结果["风险评分"] = 随机风险
                    模拟结果["风险等级"] = 风险等级.中风险
                    模拟结果["检测到的元素"] = ["模拟检测到可能敏感内容"]
                    模拟结果["置信度"] = 0.6
                else:
                    模拟结果["风险评分"] = 随机风险
                    模拟结果["风险等级"] = 风险等级.安全
                    模拟结果["检测到的元素"] = ["未检测到明显风险"]
                    模拟结果["置信度"] = 0.9
            else:
                模拟结果["分析状态"] = "不支持的图像格式"
               模拟结果["风险等级"] = 风险等级.低风险
        
        except Exception as e:
            模拟结果["分析状态"] = f"分析失败: {e}"
           模拟结果["风险等级"] = 风险等级.中风险
        
        return 模拟结果
    
    def 分析视频内容(self, 视频路径: str) -> Dict[str, Any]:
        """分析视频内容（模拟实现）"""
        # 视频分析通常更复杂，涉及多帧分析和音频分析
        模拟结果 = {
            "分析状态": "模拟视频分析完成",
            "视频时长": "未知",
            "关键帧分析": [],
            "音频分析": {},
            "风险评分": 0.0,
            "风险等级": 风险等级.安全,
            "分析详情": "这是模拟的视频分析结果"
        }
        
        try:
            # 模拟视频分析
            随机风险 = hash(视频路径) % 100 / 100.0
            
            if 随机风险 > 0.8:
                模拟结果["风险评分"] = 随机风险
                模拟结果["风险等级"] = 风险等级.高风险
                模拟结果["关键帧分析"] = ["模拟检测到多帧敏感内容"]
            elif 随机风险 > 0.5:
                模拟结果["风险评分"] = 随机风险
                模拟结果["风险等级"] = 风险等级.中风险
                模拟结果["关键帧分析"] = ["模拟检测到部分敏感内容"]
            else:
                模拟结果["风险评分"] = 随机风险
                模拟结果["风险等级"] = 风险等级.安全
                模拟结果["关键帧分析"] = ["未检测到明显风险"]
        
        except Exception as e:
            模拟结果["分析状态"] = f"分析失败: {e}"
        
        return 模拟结果

class 文本语义扫描器:
    """文本语义扫描器"""
    def __init__(self):
        self.配置管理器 = 获取配置管理器()
        self.安全识别器 = Google级安全识别器()
        self.日志器 = logging.getLogger('文本语义扫描器')
        
    def 扫描文本内容(self, 内容: str, 上下文: str = "") -> Dict[str, Any]:
        """扫描文本内容"""
        扫描开始时间 = time.time()
        
        try:
            # 深度语义扫描
            语义扫描结果 = self.安全识别器.深度语义扫描(内容, 上下文)
            
            # 风险评估
            风险等级 = self.评估风险等级(语义扫描结果["总体风险评分"])
            
            # 生成扫描报告
            扫描报告 = {
                "扫描状态": "完成",
                "扫描时间": time.time() - 扫描开始时间,
                "内容长度": len(内容),
                "风险等级": 风险等级,
                "风险评分": 语义扫描结果["总体风险评分"],
                "详细分析": 语义扫描结果,
                "建议措施": self.生成建议措施(语义扫描结果, 风险等级)
            }
            
            return 扫描报告
            
        except Exception as e:
            self.日志器.error(f"文本扫描失败: {e}")
            return {
                "扫描状态": "失败",
                "错误信息": str(e),
                "风险等级": 风险等级.中风险,
                "风险评分": 0.5,
                "建议措施": ["扫描失败，建议人工审核"]
            }
    
    def 评估风险等级(self, 风险评分: float) -> 风险等级:
        """根据风险评分评估风险等级"""
        if 风险评分 >= 0.8:
            return 风险等级.危险
        elif 风险评分 >= 0.6:
            return 风险等级.高风险
        elif 风险评分 >= 0.4:
            return 风险等级.中风险
        elif 风险评分 >= 0.2:
            return 风险等级.低风险
        else:
            return 风险等级.安全
    
    def 生成建议措施(self, 扫描结果: Dict[str, Any], 风险等级: 风险等级) -> List[str]:
        """生成建议措施"""
        措施列表 = []
        
        if 风险等级 in [风险等级.危险, 风险等级.高风险]:
            措施列表.append("立即阻止内容发布")
            措施列表.append("记录安全事件并通知管理员")
            if 扫描结果["表面风险"]:
                措施列表.append("删除或修改高风险关键词")
        
        elif 风险等级 == 风险等级.中风险:
            措施列表.append("建议人工审核")
            措施列表.append("记录审核日志")
            if 扫描结果["深层风险"]:
                措施列表.append("检查语义上下文是否恰当")
        
        elif 风险等级 == 风险等级.低风险:
            措施列表.append("可正常发布，但建议关注")
        
        else:  # 安全
            措施列表.append("内容安全，可正常发布")
        
        # 基于具体风险类型的建议
        for 风险项 in 扫描结果["表面风险"]:
            风险类型 = 风险项["风险类型"]
            if 风险类型 == "政治敏感":
                措施列表.append("避免涉及敏感政治话题")
            elif 风险类型 == "暴力内容":
                措施列表.append("减少暴力描写，或添加警示")
            elif 风险类型 == "色情内容":
                措施列表.append("避免露骨性描写")
        
        return 措施列表

class 实时风险监控器:
    """实时风险监控器"""
    def __init__(self):
        self.配置管理器 = 获取配置管理器()
        self.日志器 = logging.getLogger('实时风险监控器')
        
        # 监控状态
        self.监控指标 = defaultdict(list)
        self.风险阈值 = self.配置管理器.获取配置("安全设置.风险等级阈值", 0.7)
        self.最近警报 = []
        
        # 启动监控线程
        self.监控线程 = threading.Thread(target=self.监控循环, daemon=True)
        self.监控运行中 = True
        self.监控线程.start()
    
    def 监控循环(self):
        """监控循环"""
        while self.监控运行中:
            try:
                # 检查风险指标
                self.检查风险指标()
                
                # 清理旧数据
                self.清理历史数据()
                
                # 间隔时间
                time.sleep(60)  # 每分钟检查一次
                
            except Exception as e:
                self.日志器.error(f"监控循环错误: {e}")
                time.sleep(30)  # 出错后等待30秒
    
    def 检查风险指标(self):
        """检查风险指标"""
        当前时间 = time.time()
        
        # 检查最近的风险事件
        最近风险事件 = [
            事件 for 事件 in self.最近警报
            if 当前时间 - 事件["时间"] < 300  # 最近5分钟
        ]
        
        if len(最近风险事件) > 10:  # 5分钟内超过10个风险事件
            self.触发风险警报("高频风险事件", f"5分钟内检测到{len(最近风险事件)}个风险事件")
        
        # 检查高风险内容比例
        总内容数 = self.监控指标.get("总内容数", [0])[-1]
        高风险内容数 = self.监控指标.get("高风险内容数", [0])[-1]
        
        if 总内容数 > 0 and 高风险内容数 / 总内容数 > 0.1:  # 高风险内容超过10%
            self.触发风险警报("高风险内容比例过高", f"高风险内容比例: {高风险内容数/总内容数:.1%}")
    
    def 触发风险警报(self, 警报类型: str, 警报信息: str):
        """触发风险警报"""
        警报记录 = {
            "类型": 警报类型,
            "信息": 警报信息,
            "时间": time.time(),
            "级别": "警告"
        }
        
        self.最近警报.append(警报记录)
        self.日志器.warning(f"风险警报: {警报类型} - {警报信息}")
        
        # 限制警报数量
        if len(self.最近警报) > 50:
            self.最近警报 = self.最近警报[-50:]
    
    def 记录内容审核(self, 审核结果: 审核结果):
        """记录内容审核结果"""
        当前时间 = time.time()
        
        # 更新监控指标
        self.监控指标["总内容数"].append(当前时间)
        
        if 审核结果.风险等级 in [风险等级.高风险, 风险等级.危险]:
            self.监控指标["高风险内容数"].append(当前时间)
            
            # 记录高风险事件
            风险事件 = {
                "时间": 当前时间,
                "风险等级": 审核结果.风险等级.value,
                "风险评分": 审核结果.风险评分,
                "内容类型": 审核结果.内容类型.value
            }
            self.最近警报.append(风险事件)
    
    def 清理历史数据(self):
        """清理历史数据"""
        当前时间 = time.time()
        保留时间 = 当前时间 - 3600  # 保留最近1小时数据
        
        for 指标类型 in self.监控指标:
            self.监控指标[指标类型] = [
                数据 for 数据 in self.监控指标[指标类型]
                if 数据 > 保留时间
            ]
    
    def 获取监控状态(self) -> Dict[str, Any]:
        """获取监控状态"""
        当前时间 = time.time()
        
        # 计算最近1小时的数据
        最近1小时数据 = {
            "总内容数": len([数据 for 数据 in self.监控指标.get("总内容数", []) if 数据 > 当前时间 - 3600]),
            "高风险内容数": len([数据 for 数据 in self.监控指标.get("高风险内容数", []) if 数据 > 当前时间 - 3600]),
            "最近警报数": len([警报 for 警报 in self.最近警报 if 警报["时间"] > 当前时间 - 3600])
        }
        
        return {
            "监控状态": "运行中" if self.监控运行中 else "已停止",
            "最近1小时统计": 最近1小时数据,
            "当前风险阈值": self.风险阈值,
            "最近警报": self.最近警报[-5:]  # 最近5个警报
        }
    
    def 停止监控(self):
        """停止监控"""
        self.监控运行中 = False

class 三级审核系统:
    """三级审核系统 - 主审核引擎"""
    def __init__(self):
        self.配置管理器 = 获取配置管理器()
        self.安全识别器 = Google级安全识别器()
        self.视觉分析器 = 视觉内容分析器()
        self.文本扫描器 = 文本语义扫描器()
        self.风险监控器 = 实时风险监控器()
        self.日志器 = logging.getLogger('三级审核系统')
        
        # 审核配置
        self.当前模式 = 审核模式.开启
        self.自定义关键词库 = set()
        self.审核历史 = []
        self.安全事件记录 = []
        
        # 加载配置
        self.加载审核配置()
    
    def 加载审核配置(self):
        """加载审核配置"""
        安全配置 = self.配置管理器.获取安全配置()
        
        # 设置审核模式
        模式配置 = 安全配置.get("审核模式", "开启")
        self.当前模式 = 审核模式(模式配置)
        
        # 加载自定义关键词
        自定义关键词 = 安全配置.get("自定义关键词", [])
        self.自定义关键词库 = set(自定义关键词)
        
        self.日志器.info(f"审核系统初始化完成 - 模式: {self.当前模式.value}")
    
    def 设置审核模式(self, 模式: 审核模式, 自定义关键词: List[str] = None):
        """设置审核模式"""
        self.当前模式 = 模式
        
        if 模式 == 审核模式.自定义 and 自定义关键词:
            self.自定义关键词库 = set(自定义关键词)
        
        # 保存配置
        self.配置管理器.设置配置("安全设置.审核模式", 模式.value)
        if 自定义关键词:
            self.配置管理器.设置配置("安全设置.自定义关键词", 自定义关键词)
        
        self.日志器.info(f"审核模式已设置为: {模式.value}")
    
    def 添加自定义关键词(self, 关键词: str):
        """添加自定义关键词"""
        self.自定义关键词库.add(关键词)
        
        # 更新配置
        当前关键词 = list(self.自定义关键词库)
        self.配置管理器.设置配置("安全设置.自定义关键词", 当前关键词)
        
        self.日志器.info(f"已添加自定义关键词: {关键词}")
    
    def 移除自定义关键词(self, 关键词: str):
        """移除自定义关键词"""
        if 关键词 in self.自定义关键词库:
            self.自定义关键词库.remove(关键词)
            
            # 更新配置
            当前关键词 = list(self.自定义关键词库)
            self.配置管理器.设置配置("安全设置.自定义关键词", 当前关键词)
            
            self.日志器.info(f"已移除自定义关键词: {关键词}")
    
    def 审核内容(self, 内容: Any, 内容类型: 内容类型, 上下文: str = "") -> 审核结果:
        """审核内容"""
        审核开始时间 = time.time()
        审核ID = hashlib.md5(f"{内容}{审核开始时间}".encode()).hexdigest()[:8]
        
        try:
            # 根据审核模式处理
            if self.当前模式 == 审核模式.关闭:
                return self.创建通过审核结果(审核ID, 内容类型, 审核开始时间)
            
            elif self.当前模式 == 审核模式.自定义:
                return self.自定义模式审核(内容, 内容类型, 审核ID, 审核开始时间, 上下文)
            
            else:  # 开启模式
                return self.全面模式审核(内容, 内容类型, 审核ID, 审核开始时间, 上下文)
                
        except Exception as e:
            self.日志器.error(f"审核过程出错: {e}")
            return self.创建失败审核结果(审核ID, 内容类型, 审核开始时间, str(e))
    
    def 全面模式审核(self, 内容: Any, 内容类型: 内容类型, 审核ID: str, 开始时间: float, 上下文: str) -> 审核结果:
        """全面模式审核"""
        if 内容类型 == 内容类型.文本:
            return self.审核文本内容(内容, 审核ID, 开始时间, 上下文)
        elif 内容类型 == 内容类型.图像:
            return self.审核图像内容(内容, 审核ID, 开始时间)
        elif 内容类型 == 内容类型.视频:
            return self.审核视频内容(内容, 审核ID, 开始时间)
        else:
            return self.创建未知类型审核结果(审核ID, 内容类型, 开始时间)
    
    def 自定义模式审核(self, 内容: Any, 内容类型: 内容类型, 审核ID: str, 开始时间: float, 上下文: str) -> 审核结果:
        """自定义模式审核"""
        命中关键词 = []
        
        if 内容类型 == 内容类型.文本:
            # 只检查自定义关键词
            for 关键词 in self.自定义关键词库:
                if 关键词 in 内容:
                    命中关键词.append(关键词)
        
        if 命中关键词:
            return 审核结果(
                审核ID=审核ID,
                内容类型=内容类型,
                风险等级=风险等级.中风险,
                风险评分=len(命中关键词) * 0.2,
                审核模式=审核模式.自定义,
                通过=False,
                发现的问题=[{
                    "问题类型": "自定义关键词命中",
                    "命中关键词": 命中关键词,
                    "风险描述": f"命中{len(命中关键词)}个自定义关键词"
                }],
                自定义关键词命中=命中关键词,
                审核时间=time.time() - 开始时间,
                审核详情={"自定义关键词检查": 命中关键词},
                建议措施=["内容包含自定义敏感词，建议修改或删除"]
            )
        else:
            return self.创建通过审核结果(审核ID, 内容类型, 开始时间)
    
    def 审核文本内容(self, 文本内容: str, 审核ID: str, 开始时间: float, 上下文: str) -> 审核结果:
        """审核文本内容"""
        # 文本语义扫描
        扫描报告 = self.文本扫描器.扫描文本内容(文本内容, 上下文)
        
        # 检查自定义关键词（即使在全面模式下也检查）
        自定义关键词命中 = []
        for 关键词 in self.自定义关键词库:
            if 关键词 in 文本内容:
                自定义关键词命中.append(关键词)
        
        # 综合风险评估
        最终风险评分 = 扫描报告["风险评分"]
        if 自定义关键词命中:
            最终风险评分 = max(最终风险评分, len(自定义关键词命中) * 0.2)
        
        最终风险等级 = self.文本扫描器.评估风险等级(最终风险评分)
        
        # 判断是否通过
        通过审核 = 最终风险等级 in [风险等级.安全, 风险等级.低风险]
        
        # 记录风险监控
        self.风险监控器.记录内容审核(审核结果(
            审核ID=审核ID,
            内容类型=内容类型.文本,
            风险等级=最终风险等级,
            风险评分=最终风险评分,
            审核模式=self.当前模式,
            通过=通过审核,
            发现的问题=扫描报告["详细分析"]["表面风险"],
            自定义关键词命中=自定义关键词命中,
            审核时间=0,
            审核详情=扫描报告,
            建议措施=[]
        ))
        
        # 创建审核结果
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型.文本,
            风险等级=最终风险等级,
            风险评分=最终风险评分,
            审核模式=self.当前模式,
            通过=通过审核,
            发现的问题=扫描报告["详细分析"]["表面风险"],
            自定义关键词命中=自定义关键词命中,
            审核时间=time.time() - 开始时间,
            审核详情=扫描报告,
            建议措施=扫描报告["建议措施"]
        )
        
        # 记录审核历史
        self.记录审核历史(审核结果实例)
        
        # 如果发现高风险，记录安全事件
        if not 通过审核:
            self.记录安全事件(审核结果实例, 文本内容[:100] + "...")
        
        return 审核结果实例
    
    def 审核图像内容(self, 图像路径: str, 审核ID: str, 开始时间: float) -> 审核结果:
        """审核图像内容"""
        # 视觉内容分析
        分析结果 = self.视觉分析器.分析图像内容(图像路径)
        
        风险等级映射 = {
            "安全": 风险等级.安全,
            "低风险": 风险等级.低风险,
            "中风险": 风险等级.中风险,
            "高风险": 风险等级.高风险
        }
        
        风险等级实例 = 风险等级映射.get(分析结果["风险等级"], 风险等级.安全)
        通过审核 = 风险等级实例 in [风险等级.安全, 风险等级.低风险]
        
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型.图像,
            风险等级=风险等级实例,
            风险评分=分析结果["风险评分"],
            审核模式=self.当前模式,
            通过=通过审核,
            发现的问题=分析结果["检测到的元素"],
            自定义关键词命中=[],
            审核时间=time.time() - 开始时间,
            审核详情=分析结果,
            建议措施=["通过图像分析检测"] if 通过审核 else ["建议人工审核图像内容"]
        )
        
        # 记录审核历史
        self.记录审核历史(审核结果实例)
        
        return 审核结果实例
    
    def 审核视频内容(self, 视频路径: str, 审核ID: str, 开始时间: float) -> 审核结果:
        """审核视频内容"""
        # 视频内容分析
        分析结果 = self.视觉分析器.分析视频内容(视频路径)
        
        风险等级映射 = {
            "安全": 风险等级.安全,
            "低风险": 风险等级.低风险,
            "中风险": 风险等级.中风险,
            "高风险": 风险等级.高风险
        }
        
        风险等级实例 = 风险等级映射.get(分析结果["风险等级"], 风险等级.安全)
        通过审核 = 风险等级实例 in [风险等级.安全, 风险等级.低风险]
        
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型.视频,
            风险等级=风险等级实例,
            风险评分=分析结果["风险评分"],
            审核模式=self.当前模式,
            通过=通过审核,
            发现的问题=分析结果["关键帧分析"],
            自定义关键词命中=[],
            审核时间=time.time() - 开始时间,
            审核详情=分析结果,
            建议措施=["通过视频分析检测"] if 通过审核 else ["建议人工审核视频内容"]
        )
        
        # 记录审核历史
        self.记录审核历史(审核结果实例)
        
        return 审核结果实例
    
    def 创建通过审核结果(self, 审核ID: str, 内容类型: 内容类型, 开始时间: float) -> 审核结果:
        """创建通过审核结果"""
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型,
            风险等级=风险等级.安全,
            风险评分=0.0,
            审核模式=self.当前模式,
            通过=True,
            发现的问题=[],
            自定义关键词命中=[],
            审核时间=time.time() - 开始时间,
            审核详情={"审核模式": self.当前模式.value},
            建议措施=["内容安全，可正常使用"]
        )
        
        self.记录审核历史(审核结果实例)
        return 审核结果实例
    
    def 创建失败审核结果(self, 审核ID: str, 内容类型: 内容类型, 开始时间: float, 错误信息: str) -> 审核结果:
        """创建失败审核结果"""
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型,
            风险等级=风险等级.中风险,
            风险评分=0.5,
            审核模式=self.当前模式,
            通过=False,
            发现的问题=[{"问题类型": "审核系统错误", "描述": 错误信息}],
            自定义关键词命中=[],
            审核时间=time.time() - 开始时间,
            审核详情={"错误信息": 错误信息},
            建议措施=["审核系统出错，建议人工审核"]
        )
        
        self.记录审核历史(审核结果实例)
        return 审核结果实例
    
    def 创建未知类型审核结果(self, 审核ID: str, 内容类型: 内容类型, 开始时间: float) -> 审核结果:
        """创建未知类型审核结果"""
        审核结果实例 = 审核结果(
            审核ID=审核ID,
            内容类型=内容类型,
            风险等级=风险等级.低风险,
            风险评分=0.3,
            审核模式=self.当前模式,
            通过=True,
            发现的问题=[{"问题类型": "未知内容类型", "描述": f"未支持的内容类型: {内容类型.value}"}],
            自定义关键词命中=[],
            审核时间=time.time() - 开始时间,
            审核详情={"内容类型": 内容类型.value},
            建议措施=["内容类型未知，建议谨慎使用"]
        )
        
        self.记录审核历史(审核结果实例)
        return 审核结果实例
    
    def 记录审核历史(self, 审核结果: 审核结果):
        """记录审核历史"""
        历史记录 = {
            "审核ID": 审核结果.审核ID,
            "内容类型": 审核结果.内容类型.value,
            "风险等级": 审核结果.风险等级.value,
            "风险评分": 审核结果.风险评分,
            "通过": 审核结果.通过,
            "审核时间": 审核结果.审核时间,
            "时间戳": time.time()
        }
        
        self.审核历史.append(历史记录)
        
        # 限制历史记录数量
        if len(self.审核历史) > 10000:
            self.审核历史 = self.审核历史[-10000:]
    
    def 记录安全事件(self, 审核结果: 审核结果, 内容摘要: str):
        """记录安全事件"""
        安全事件实例 = 安全事件(
            事件ID=审核结果.审核ID,
            内容类型=审核结果.内容类型,
            风险等级=审核结果.风险等级,
            内容摘要=内容摘要,
            审核结果=审核结果,
            处理状态="待处理",
            发生时间=time.time(),
            处理时间=None,
            处理人员=None,
            处理措施=None
        )
        
        self.安全事件记录.append(安全事件实例)
        
        # 限制安全事件数量
        if len(self.安全事件记录) > 1000:
            self.安全事件记录 = self.安全事件记录[-1000:]
    
    def 处理安全事件(self, 事件ID: str, 处理人员: str, 处理措施: str):
        """处理安全事件"""
        for 事件 in self.安全事件记录:
            if 事件.事件ID == 事件ID:
                事件.处理状态 = "已处理"
                事件.处理时间 = time.time()
                事件.处理人员 = 处理人员
                事件.处理措施 = 处理措施
                break
    
    def 获取审核统计(self) -> Dict[str, Any]:
        """获取审核统计信息"""
        总审核数 = len(self.审核历史)
        通过数 = len([记录 for 记录 in self.审核历史 if 记录["通过"]])
        拒绝数 = 总审核数 - 通过数
        
        # 风险等级统计
        风险统计 = {}
        for 风险等级 in 风险等级:
            风险统计[风险等级.value] = len([
                记录 for 记录 in self.审核历史 
                if 记录["风险等级"] == 风险等级.value
            ])
        
        # 内容类型统计
        类型统计 = {}
        for 内容类型 in 内容类型:
            类型统计[内容类型.value] = len([
                记录 for 记录 in self.审核历史 
                if 记录["内容类型"] == 内容类型.value
            ])
        
        return {
            "总审核数": 总审核数,
            "通过数": 通过数,
            "拒绝数": 拒绝数,
            "通过率": 通过数 / 总审核数 if 总审核数 > 0 else 0,
            "风险等级统计": 风险统计,
            "内容类型统计": 类型统计,
            "待处理安全事件": len([事件 for 事件 in self.安全事件记录 if 事件.处理状态 == "待处理"]),
            "监控状态": self.风险监控器.获取监控状态()
        }
    
    def 导出审核日志(self, 开始时间: float = None, 结束时间: float = None) -> List[Dict[str, Any]]:
        """导出审核日志"""
        if 开始时间 is None:
            开始时间 = 0
        if 结束时间 is None:
            结束时间 = time.time()
        
        过滤日志 = [
            记录 for 记录 in self.审核历史
            if 开始时间 <= 记录["时间戳"] <= 结束时间
        ]
        
        return 过滤日志
    
    def 导出安全事件(self, 处理状态: str = None) -> List[安全事件]:
        """导出安全事件"""
        if 处理状态:
            return [事件 for 事件 in self.安全事件记录 if 事件.处理状态 == 处理状态]
        else:
            return self.安全事件记录

# 三级审核系统单例
三级审核系统实例 = None

def 获取三级审核系统():
    """获取三级审核系统单例"""
    global 三级审核系统实例
    if 三级审核系统实例 is None:
        三级审核系统实例 = 三级审核系统()
    return 三级审核系统实例

if __name__ == "__main__":
    # 测试三级审核系统
    审核系统 = 获取三级审核系统()
    
    # 测试文本审核
    测试文本 = "这是一段包含暴力和政治敏感内容的测试文本。涉及杀人、暴力等内容。"
    审核结果 = 审核系统.审核内容(测试文本, 内容类型.文本)
    
    print("文本审核结果:")
    print(f"审核ID: {审核结果.审核ID}")
    print(f"风险等级: {审核结果.风险等级.value}")
    print(f"风险评分: {审核结果.风险评分:.2f}")
    print(f"是否通过: {审核结果.通过}")
    print(f"发现问题: {[问题['风险类型'] for 问题 in 审核结果.发现的问题]}")
    
    # 测试统计信息
    统计 = 审核系统.获取审核统计()
    print(f"\n审核统计: {统计}")
    
    # 测试自定义模式
    审核系统.设置审核模式(审核模式.自定义, ["测试关键词"])
    自定义审核结果 = 审核系统.审核内容("这段文本包含测试关键词", 内容类型.文本)
    print(f"\n自定义模式审核: {自定义审核结果.通过}")